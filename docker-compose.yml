version: '3.8'

services:
  backend:
    build: ./backend
    container_name: automodeler_backend
    env_file:
      - ./backend/.env.example
    # ADDED THIS SECTION
    environment:
      - PYTHONPATH=/app
    ports:
      - "8000:8000"
    volumes:
      - ./backend:/app
      - ./scripts:/app/scripts
      - dvc_cache:/app/.dvc/cache
      - mlruns:/app/mlruns
    depends_on:
      - redis
    command: bash -c "uvicorn app.main:app --host 0.0.0.0 --port 8000 --reload"

  worker:
    build: ./backend
    container_name: automodeler_worker
    env_file:
      - ./backend/.env.example
    environment:
      - PYTHONPATH=/app
    volumes:
      - ./backend:/app
      - dvc_cache:/app/.dvc/cache
      - mlruns:/app/mlruns
    depends_on:
      - redis
    command: bash -c "celery -A app.worker.celery_app:celery_app worker -l info"

  frontend:
    build: ./frontend
    container_name: automodeler_frontend
    ports:
      - "3000:3000"
    volumes:
      - ./frontend:/app
      - /app/node_modules
      - /app/.next
    environment:
      - NEXT_PUBLIC_API_URL=http://localhost:8000

  redis:
    image: redis:6.2-alpine
    container_name: automodeler_redis
    ports:
      - "6379:6379"

  mlflow:
    image: python:3.9-slim
    container_name: automodeler_mlflow
    ports:
      - "5001:5001"
    volumes:
      - mlruns:/app/mlruns
    command: >
      bash -c "pip install mlflow boto3 &&
      mlflow server
      --backend-store-uri file:///app/mlruns
      --default-artifact-root file:///app/mlruns
      --host 0.0.0.0
      --port 5001"

volumes:
  dvc_cache:
  mlruns: